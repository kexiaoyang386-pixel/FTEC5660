{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3f861133"
      },
      "outputs": [],
      "source": [
        "!pip install langchain-google-genai langchain-core langchain-experimental\n",
        "!pip install yfinance"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_student_id(student_id: int) -> str:\n",
        "    \"\"\"\n",
        "    Reversibly encode a student ID using an affine cipher.\n",
        "\n",
        "    Args:\n",
        "        student_id (int): Original student ID (non-negative integer)\n",
        "\n",
        "    Returns:\n",
        "        str: Encoded ID as a zero-padded string\n",
        "    \"\"\"\n",
        "    if student_id < 0:\n",
        "        raise ValueError(\"student_id must be non-negative\")\n",
        "\n",
        "    M = 10**8\n",
        "    a = 137\n",
        "    b = 911\n",
        "\n",
        "    encoded = (a * student_id + b) % M\n",
        "    return f\"{encoded:08d}\""
      ],
      "metadata": {
        "id": "FPhY3o16M29e"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encode_student_id(1155238340)"
      ],
      "metadata": {
        "id": "9VgyZFO6NAd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -X POST https://www.moltbook.com/api/v1/agents/register \\\n",
        "  -H \"Content-Type: application/json\" \\\n",
        "  -d '{\"name\": \"Agent_67653491\", \"description\": \"My Moltbook Agent\"}'"
      ],
      "metadata": {
        "id": "niQuV_4Tfw50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "from langchain_core.tools import tool\n",
        "from google.colab import userdata\n",
        "\n",
        "MOLTBOOK_API_KEY = userdata.get('MOLTBOOK_API_KEY').strip()\n",
        "BASE_URL = \"https://www.moltbook.com/api/v1\"\n",
        "\n",
        "HEADERS = {\n",
        "    \"Authorization\": f\"Bearer {MOLTBOOK_API_KEY}\",\n",
        "    \"Content-Type\": \"application/json\"\n",
        "}\n",
        "\n",
        "\n",
        "# ---------- FEED ----------\n",
        "@tool\n",
        "def get_feed(sort: str = \"new\", limit: int = 10) -> dict:\n",
        "    \"\"\"Fetch Moltbook feed.\"\"\"\n",
        "    r = requests.get(\n",
        "        f\"{BASE_URL}/feed\",\n",
        "        headers=HEADERS,\n",
        "        params={\"sort\": sort, \"limit\": limit},\n",
        "        timeout=15\n",
        "    )\n",
        "    return r.json()\n",
        "\n",
        "# ---------- SEARCH ----------\n",
        "@tool\n",
        "def search_moltbook(query: str, type: str = \"all\") -> dict:\n",
        "    \"\"\"Semantic search Moltbook posts, comments, agents.\"\"\"\n",
        "    r = requests.get(\n",
        "        f\"{BASE_URL}/search\",\n",
        "        headers=HEADERS,\n",
        "        params={\"q\": query, \"type\": type},\n",
        "        timeout=15\n",
        "    )\n",
        "    return r.json()\n",
        "\n",
        "# ---------- POST ----------\n",
        "@tool\n",
        "def create_post(submolt: str, title: str, content: str) -> dict:\n",
        "    \"\"\"Create a new text post.\"\"\"\n",
        "    payload = {\n",
        "        \"submolt\": submolt,\n",
        "        \"title\": title,\n",
        "        \"content\": content\n",
        "    }\n",
        "    r = requests.post(\n",
        "        f\"{BASE_URL}/posts\",\n",
        "        headers=HEADERS,\n",
        "        json=payload,\n",
        "        timeout=15\n",
        "    )\n",
        "    return r.json()\n",
        "\n",
        "# ---------- COMMENT ----------\n",
        "@tool\n",
        "def comment_post(post_id: str, content: str) -> dict:\n",
        "    \"\"\"Comment on a post.\"\"\"\n",
        "    r = requests.post(\n",
        "        f\"{BASE_URL}/posts/{post_id}/comments\",\n",
        "        headers=HEADERS,\n",
        "        json={\"content\": content},\n",
        "        timeout=15\n",
        "    )\n",
        "    return r.json()\n",
        "\n",
        "# ---------- VOTE ----------\n",
        "@tool\n",
        "def upvote_post(post_id: str) -> dict:\n",
        "    \"\"\"Upvote a post.\"\"\"\n",
        "    r = requests.post(\n",
        "        f\"{BASE_URL}/posts/{post_id}/upvote\",\n",
        "        headers=HEADERS,\n",
        "        timeout=15\n",
        "    )\n",
        "    return r.json()\n"
      ],
      "metadata": {
        "id": "XUK8gPZTcFwE"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def subscribe_community(submolt_name: str) -> dict:\n",
        "    \"\"\"订阅 Moltbook 社区，参数为社区ID，例如 m/ftec5660\"\"\"\n",
        "    url = f\"{BASE_URL}/submolts/{submolt_name}/subscribe\"\n",
        "    try:\n",
        "        response = requests.post(url, headers=HEADERS, timeout=15)\n",
        "        return {\"statusCode\": response.status_code, \"response\": response.json()}\n",
        "    except Exception as e:\n",
        "        return {\"statusCode\": 500, \"error\": str(e)}"
      ],
      "metadata": {
        "id": "TqlptZ33-BOh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [get_feed, search_moltbook, create_post, comment_post, upvote_post, subscribe_community]"
      ],
      "metadata": {
        "id": "TTfolvRWC6Fj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SYSTEM_PROMPT = \"\"\"\n",
        "You are a Moltbook AI agent.\n",
        "\n",
        "Your purpose:\n",
        "- Discover valuable AI / ML / agentic system discussions\n",
        "- Engage thoughtfully and selectively\n",
        "- NEVER spam\n",
        "- NEVER repeat content\n",
        "- Respect rate limits\n",
        "\n",
        "Rules:\n",
        "1. Before posting, ALWAYS search Moltbook to avoid duplication.\n",
        "2. Only comment if you add new insight.\n",
        "3. Upvote only genuinely useful content.\n",
        "4. If uncertain, do nothing.\n",
        "5. Prefer short, clear, professional language.\n",
        "6. If a human gives an instruction, obey it exactly.\n",
        "\n",
        "Available tools:\n",
        "- get_feed\n",
        "- search_moltbook\n",
        "- create_post\n",
        "- comment_post\n",
        "- upvote_post\n",
        "- subscribe_community\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "lr0R7Sg3cWW9"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI"
      ],
      "metadata": {
        "id": "aKxSTWQrv2sv"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    google_api_key=\"AIzaSyAfPh46scRysGVa-FFMVvpRsNSDgvpHshM\",\n",
        "    temperature=0,\n",
        ")"
      ],
      "metadata": {
        "id": "Shk6eVl84RpF"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.messages import ToolMessage\n",
        "import time\n",
        "import json\n",
        "from datetime import datetime\n",
        "from typing import Any\n",
        "from langchain_core.messages import HumanMessage"
      ],
      "metadata": {
        "id": "ZpYj5CfHcbDW"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def log(section: str, message: str):\n",
        "    ts = datetime.utcnow().strftime(\"%H:%M:%S\")\n",
        "    print(f\"[{ts}] [{section}] {message}\")\n",
        "\n",
        "def pretty(obj: Any, max_len: int = 800) -> str:\n",
        "    text = json.dumps(obj, indent=2, ensure_ascii=False, default=str)\n",
        "    return text if len(text) <= max_len else text[:max_len] + \"\\n...[truncated]\"\n",
        "\n",
        "def moltbook_agent_loop(\n",
        "    instruction: str | None = None,\n",
        "    max_turns: int = 8,\n",
        "    verbose: bool = True,\n",
        "):\n",
        "    log(\"INIT\", \"Starting Moltbook agent loop\")\n",
        "\n",
        "    messages: List[Any] = [\n",
        "        HumanMessage(content=f\"\"\"\n",
        "你是一个自主 Moltbook 智能体，你的任务是：\n",
        "1. 先完成认证（已通过API KEY配置）\n",
        "2. 订阅 m/ftec5660\n",
        "3. 对帖子 47ff50f3-8255-4dee-87f4-2c3637c7351c 进行点赞和评论\n",
        "你可以使用以下工具：\n",
        "{json.dumps([\"get_feed\", \"search_moltbook\", \"create_post\", \"comment_post\", \"upvote_post\", \"subscribe_community\"], indent=2)}\n",
        "\n",
        "现在执行用户指令：{instruction}\n",
        "\"\"\")\n",
        "    ]\n",
        "\n",
        "    for turn in range(max_turns):\n",
        "        log(\"TURN\", f\"Turn {turn+1}/{max_turns} started\")\n",
        "\n",
        "        if verbose:\n",
        "            log(\"LLM\", \"Calling LLM for next step...\")\n",
        "        response = llm.invoke(messages, tools=tools)\n",
        "        if verbose:\n",
        "            log(\"LLM_CONTENT\", response.content if response.content else \"<empty>\")\n",
        "\n",
        "        if response.tool_calls:\n",
        "            if verbose:\n",
        "                log(\"LLM_TOOL_CALLS\", pretty(response.tool_calls))\n",
        "\n",
        "            for tool_call in response.tool_calls:\n",
        "                tool_name = tool_call[\"name\"]\n",
        "                tool_args = tool_call[\"args\"]\n",
        "                tool_id = tool_call[\"id\"]\n",
        "\n",
        "                if verbose:\n",
        "                    log(\"TOOL\", f\"[{tool_id}] Calling '{tool_name}'\")\n",
        "                    log(\"TOOL_ARGS\", pretty(tool_args))\n",
        "\n",
        "                for t in tools:\n",
        "                    if t.name == tool_name:\n",
        "                        result = t.invoke(tool_args)\n",
        "                        break\n",
        "                else:\n",
        "                    result = {\"success\": False, \"error\": f\"Unknown tool: {tool_name}\"}\n",
        "\n",
        "                if verbose:\n",
        "                    log(\"TOOL_RESULT\", f\"{tool_name} finished\")\n",
        "                    log(\"TOOL_OUTPUT\", pretty(result))\n",
        "\n",
        "                messages.append(\n",
        "                    ToolMessage(\n",
        "                        tool_call_id=tool_id,\n",
        "                        content=json.dumps(result)\n",
        "                    )\n",
        "                )\n",
        "        else:\n",
        "            log(\"DONE\", \"No more tool calls. Task completed.\")\n",
        "            break\n",
        "\n",
        "    log(\"FINISH\", \"Agent loop finished\")\n",
        "    return messages\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    final_messages = moltbook_agent_loop(\n",
        "        instruction=\"\"\"\n",
        "请完成以下任务：\n",
        "1. 订阅 m/ftec5660\n",
        "2. 对帖子 ID 47ff50f3-8255-4dee-87f4-2c3637c7351c 进行点赞\n",
        "3. 在该帖子下评论：\"Great post! Thanks for sharing.\"\n",
        "\"\"\"\n",
        "    )"
      ],
      "metadata": {
        "id": "OxGq9tnhDk3B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}