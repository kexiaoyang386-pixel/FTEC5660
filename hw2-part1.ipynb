{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install requests PyPDF2 gdown\n",
        "!pip install 'markitdown[pdf]'\n",
        "!pip install langchain_mcp_adapters langchain_google_genai langchain-openai"
      ],
      "metadata": {
        "id": "Hrdfpmv9nMpw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "GEMINI_VERTEX_API_KEY = userdata.get('zhao')"
      ],
      "metadata": {
        "id": "ueILmCPHci9v"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\",\n",
        "                             api_key=GEMINI_VERTEX_API_KEY,\n",
        "                             vertexai=True,\n",
        "                             temperature=0)"
      ],
      "metadata": {
        "id": "RSp9s5koopwa"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gdown\n",
        "\n",
        "folder_id = \"1adYKq7gSSczFP3iikfA8Er-HSZP6VM7D\"\n",
        "folder_url = f\"https://drive.google.com/drive/folders/{folder_id}\"\n",
        "\n",
        "output_dir = \"downloaded_cvs\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "gdown.download_folder(\n",
        "    url=folder_url,\n",
        "    output=output_dir,\n",
        "    quiet=False,\n",
        "    use_cookies=False\n",
        ")"
      ],
      "metadata": {
        "id": "1kCCp8DwPF4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================\n",
        "#  Load and display all CV PDFs in order\n",
        "# =====================================================\n",
        "import os\n",
        "from markitdown import MarkItDown\n",
        "\n",
        "cv_dir = \"downloaded_cvs\"\n",
        "\n",
        "# Initialize MarkItDown\n",
        "md = MarkItDown(enable_plugins=False)\n",
        "\n",
        "# Collect and sort PDFs numerically\n",
        "pdf_files = sorted(\n",
        "    [f for f in os.listdir(cv_dir) if f.lower().endswith(\".pdf\")],\n",
        "    key=lambda x: int(\"\".join(filter(str.isdigit, x)))  # CV_1.pdf â†’ 1\n",
        ")\n",
        "\n",
        "all_cvs = []\n",
        "\n",
        "for pdf_name in pdf_files:\n",
        "    pdf_path = os.path.join(cv_dir, pdf_name)\n",
        "    result = md.convert(pdf_path)\n",
        "\n",
        "    all_cvs.append({\n",
        "        \"file\": pdf_name,\n",
        "        \"text\": result.text_content\n",
        "    })\n",
        "\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"ðŸ“„ {pdf_name}\")\n",
        "    print(\"=\" * 80)\n",
        "    print(result.text_content)\n",
        "    print(\"\\n\\n\")\n"
      ],
      "metadata": {
        "id": "2akmVn9LODIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import json\n",
        "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
        "\n",
        "client = MultiServerMCPClient({\n",
        "    \"social_graph\": {\n",
        "        \"transport\": \"http\",\n",
        "        \"url\": \"https://ftec5660.ngrok.app/mcp\",\n",
        "        \"headers\": {\"ngrok-skip-browser-warning\": \"true\"}\n",
        "    }\n",
        "})\n",
        "\n",
        "mcp_tools = await client.get_tools()\n",
        "for tool in mcp_tools:\n",
        "    print(tool.name)\n",
        "    print(tool.description)\n",
        "    print(tool.args)\n",
        "    print(\"\\n\\n------------------------------------------------------\\n\\n\")"
      ],
      "metadata": {
        "id": "6h0311KbN9A3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_structured_info(cv_text):\n",
        "    prompt = f\"\"\"\n",
        "ä»Žä»¥ä¸‹ç®€åŽ†ä¸­æå–ç»“æž„åŒ–ä¿¡æ¯ï¼Œä¸¥æ ¼æŒ‰ç…§ç¤ºä¾‹æ ¼å¼è¿”å›žJSONï¼Œä¸è¦ç”¨ä»£ç å—åŒ…è£¹ï¼Œä¸è¦ä»»ä½•é¢å¤–è§£é‡Šï¼š\n",
        "{{\n",
        "  \"name\": \"å€™é€‰äººå…¨å\",\n",
        "  \"location\": \"åŸŽå¸‚/å›½å®¶\",\n",
        "  \"work_experience\": [\n",
        "    {{\n",
        "      \"company\": \"å…¬å¸å\",\n",
        "      \"title\": \"èŒä½\",\n",
        "      \"start_year\": å¼€å§‹å¹´ä»½,\n",
        "      \"end_year\": ç»“æŸå¹´ä»½æˆ–null\n",
        "    }}\n",
        "  ],\n",
        "  \"education\": [\n",
        "    {{\n",
        "      \"school\": \"å­¦æ ¡å\",\n",
        "      \"degree\": \"å­¦ä½\",\n",
        "      \"field\": \"ä¸“ä¸š\",\n",
        "      \"start_year\": å¼€å§‹å¹´ä»½,\n",
        "      \"end_year\": ç»“æŸå¹´ä»½\n",
        "    }}\n",
        "  ]\n",
        "}}\n",
        "\n",
        "ç®€åŽ†æ–‡æœ¬ï¼š\n",
        "{cv_text}\n",
        "\"\"\"\n",
        "    response = llm.invoke(prompt)\n",
        "\n",
        "    # æ¸…æ´—å’Œè§£æž\n",
        "    try:\n",
        "        return json.loads(response.content.strip())\n",
        "    except json.JSONDecodeError:\n",
        "        cleaned = response.content.strip().replace(\"```json\", \"\").replace(\"```\", \"\")\n",
        "        try:\n",
        "            return json.loads(cleaned)\n",
        "        except:\n",
        "            print(f\"è§£æžå¤±è´¥ï¼ŒåŽŸå§‹è¿”å›žï¼š{response.content}\")\n",
        "            return {}\n",
        "\n",
        "# 3. æ‰¹é‡æå–å¹¶æ‰“å°ç»“æžœ\n",
        "structured_cvs = []\n",
        "for cv in all_cvs:\n",
        "    print(f\"æ­£åœ¨æå–ç»“æž„åŒ–ä¿¡æ¯ï¼š{cv['file']}\")\n",
        "    structured_data = extract_structured_info(cv[\"text\"])\n",
        "    structured_cvs.append({\n",
        "        \"file\": cv[\"file\"],\n",
        "        \"structured\": structured_data\n",
        "    })\n",
        "\n",
        "# æ‰“å°ç»“æžœ\n",
        "for cv in structured_cvs:\n",
        "    print(f\"\\n=== {cv['file']} ===\")\n",
        "    print(json.dumps(cv[\"structured\"], indent=2))"
      ],
      "metadata": {
        "id": "0YXIWU6s6-Aq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
        "\n",
        "async def connect_mcp():\n",
        "\n",
        "    client = MultiServerMCPClient({\n",
        "        \"social_graph\": {\n",
        "            \"transport\": \"http\",\n",
        "            \"url\": \"https://ftec5660.ngrok.app/mcp\",\n",
        "            \"headers\": {\"ngrok-skip-browser-warning\": \"true\"}\n",
        "        }\n",
        "    })\n",
        "\n",
        "\n",
        "    try:\n",
        "        tools = await client.get_tools()\n",
        "        print(\"âœ… MCP æœåŠ¡å™¨è¿žæŽ¥æˆåŠŸï¼\")\n",
        "        print(\"å¯ç”¨å·¥å…·ï¼š\")\n",
        "        for tool in tools:\n",
        "            print(f\"- {tool.name}: {tool.description}\")\n",
        "        return client\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ è¿žæŽ¥å¤±è´¥: {type(e).__name__}: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "mcp_client = await connect_mcp()"
      ],
      "metadata": {
        "id": "6oureb6O-8XO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async def test_search_with_session():\n",
        "\n",
        "    if mcp_client is None:\n",
        "        print(\"âŒ å®¢æˆ·ç«¯æœªè¿žæŽ¥ï¼Œæ— æ³•åˆ›å»ºä¼šè¯\")\n",
        "        return\n",
        "\n",
        "\n",
        "    first_cv = structured_cvs[0]\n",
        "    name = first_cv[\"structured\"][\"name\"]\n",
        "\n",
        "\n",
        "    try:\n",
        "        async with mcp_client.session(\"social_graph\") as session:\n",
        "            print(f\"ðŸ”Ž æ­£åœ¨æœç´¢: {name}\")\n",
        "\n",
        "            result = await session.call_tool(\n",
        "                name=\"search_facebook_users\",\n",
        "                arguments={\n",
        "                    \"q\": name,\n",
        "                    \"limit\": 1,\n",
        "                    \"fuzzy\": True\n",
        "                }\n",
        "            )\n",
        "            print(\"âœ… æœç´¢ç»“æžœ:\", result)\n",
        "            return result\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ ä¼šè¯è°ƒç”¨å¤±è´¥: {type(e).__name__}: {str(e)}\")\n",
        "\n",
        "\n",
        "await test_search_with_session()"
      ],
      "metadata": {
        "id": "GANY0J1M_-S8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async def get_user_profile():\n",
        "\n",
        "    user_id = 8\n",
        "\n",
        "    try:\n",
        "        async with mcp_client.session(\"social_graph\") as session:\n",
        "            print(f\"ðŸ‘¤ æ­£åœ¨èŽ·å–ç”¨æˆ· ID {user_id} çš„èµ„æ–™...\")\n",
        "            profile = await session.call_tool(\n",
        "                name=\"get_facebook_profile\",\n",
        "                arguments={\"user_id\": user_id}\n",
        "            )\n",
        "            print(\"âœ… ç”¨æˆ·èµ„æ–™èŽ·å–æˆåŠŸï¼\")\n",
        "            print(profile)\n",
        "            return profile\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ èŽ·å–ç”¨æˆ·èµ„æ–™å¤±è´¥: {type(e).__name__}: {str(e)}\")\n",
        "\n",
        "\n",
        "user_profile = await get_user_profile()"
      ],
      "metadata": {
        "id": "JUfrbDbBAKsv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "async def get_first_user_profile_final():\n",
        "    first_cv = structured_cvs[0]\n",
        "    candidate_name = first_cv[\"structured\"][\"name\"]\n",
        "\n",
        "\n",
        "    async with mcp_client.session(\"social_graph\") as session:\n",
        "        raw_search = await session.call_tool(\n",
        "            name=\"search_facebook_users\",\n",
        "            arguments={\"q\": candidate_name, \"limit\": 1, \"fuzzy\": True}\n",
        "        )\n",
        "\n",
        "\n",
        "    json_str = raw_search.content[0].text\n",
        "    search_result_data = json.loads(json_str)\n",
        "\n",
        "    if not search_result_data:\n",
        "        print(\"âŒ æ²¡æ‰¾åˆ°ç”¨æˆ·\")\n",
        "        return None\n",
        "\n",
        "    user_id = search_result_data[0][\"id\"]\n",
        "    print(f\"âœ… æ‰¾åˆ°ç”¨æˆ· ID: {user_id}\")\n",
        "\n",
        "\n",
        "    async with mcp_client.session(\"social_graph\") as session:\n",
        "        raw_profile = await session.call_tool(\n",
        "            name=\"get_facebook_profile\",\n",
        "            arguments={\"user_id\": user_id}\n",
        "        )\n",
        "\n",
        "\n",
        "    profile_json_str = raw_profile.content[0].text\n",
        "    profile_data = json.loads(profile_json_str)\n",
        "\n",
        "    print(\"âœ… ç”¨æˆ·èµ„æ–™è§£æžæˆåŠŸï¼š\")\n",
        "    print(json.dumps(profile_data, indent=2, ensure_ascii=False))\n",
        "    return profile_data\n",
        "\n",
        "\n",
        "user_profile = await get_first_user_profile_final()"
      ],
      "metadata": {
        "id": "zYluJ24RBKvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_first_cv_discrepancies():\n",
        "    cv_data = structured_cvs[0][\"structured\"]\n",
        "\n",
        "    discrepancies = []\n",
        "\n",
        "\n",
        "    cv_school = cv_data[\"education\"][0][\"school\"] if cv_data.get(\"education\") else \"N/A\"\n",
        "    social_edu = user_profile.get(\"education\", \"N/A\")\n",
        "    if cv_school not in social_edu:\n",
        "        discrepancies.append({\n",
        "            \"field\": \"education\",\n",
        "            \"cv\": cv_school,\n",
        "            \"social\": social_edu,\n",
        "            \"issue\": \"å­¦æ ¡ä¸åŒ¹é…\"\n",
        "        })\n",
        "\n",
        "\n",
        "    cv_company = cv_data[\"work_experience\"][0][\"company\"] if cv_data.get(\"work_experience\") else \"N/A\"\n",
        "    social_company = user_profile.get(\"current_company\", \"N/A\")\n",
        "    if cv_company not in social_company:\n",
        "        discrepancies.append({\n",
        "            \"field\": \"current_company\",\n",
        "            \"cv\": cv_company,\n",
        "            \"social\": social_company,\n",
        "            \"issue\": \"å…¬å¸ä¸åŒ¹é…\"\n",
        "        })\n",
        "\n",
        "    print(\"ðŸ” å·®å¼‚æ£€æµ‹ç»“æžœ:\")\n",
        "    if discrepancies:\n",
        "        for d in discrepancies:\n",
        "            print(f\"- {d['issue']}: CV å£°ç§° '{d['cv']}', ç¤¾äº¤æ˜¾ç¤º '{d['social']}'\")\n",
        "    else:\n",
        "        print(\"âœ… æœªå‘çŽ°å·®å¼‚\")\n",
        "    return discrepancies\n",
        "\n",
        "\n",
        "discrepancies = detect_first_cv_discrepancies()"
      ],
      "metadata": {
        "id": "AJ2kdm-FBame"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_first_report():\n",
        "    cv_file = structured_cvs[0][\"file\"]\n",
        "    cv_name = structured_cvs[0][\"structured\"][\"name\"]\n",
        "    social_name = user_profile.get(\"display_name\", \"N/A\")\n",
        "\n",
        "    report = f\"\"\"\n",
        "# ðŸ“‹ CV éªŒè¯æŠ¥å‘Š - {cv_file}\n",
        "## åŸºæœ¬ä¿¡æ¯\n",
        "- å€™é€‰äººå§“å: {cv_name}\n",
        "- åŒ¹é…ç¤¾äº¤è´¦å·: {social_name}\n",
        "\n",
        "## ðŸ” éªŒè¯ç»“æžœ\n",
        "\"\"\"\n",
        "    if discrepancies:\n",
        "        report += f\"### âš ï¸ å‘çŽ° {len(discrepancies)} å¤„å·®å¼‚:\\n\"\n",
        "        for d in discrepancies:\n",
        "            report += f\"- {d['issue']}: CV å£°ç§° '{d['cv']}', ç¤¾äº¤æ˜¾ç¤º '{d['social']}'\\n\"\n",
        "    else:\n",
        "        report += \"### âœ… æœªå‘çŽ°æ˜Žæ˜¾å·®å¼‚ï¼Œç®€åŽ†ä¿¡æ¯åˆæ­¥éªŒè¯é€šè¿‡ã€‚\\n\"\n",
        "\n",
        "    print(report)\n",
        "    return report\n",
        "\n",
        "\n",
        "first_report = generate_first_report()"
      ],
      "metadata": {
        "id": "lGCSkIsrBipp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import json\n",
        "\n",
        "async def verify_all_cvs():\n",
        "    if mcp_client is None:\n",
        "        print(\"âŒ MCP å®¢æˆ·ç«¯æœªè¿žæŽ¥\")\n",
        "        return\n",
        "    if len(structured_cvs) == 0:\n",
        "        print(\"âŒ æ²¡æœ‰ç»“æž„åŒ–ç®€åŽ†æ•°æ®\")\n",
        "        return\n",
        "\n",
        "    final_results = []\n",
        "\n",
        "    for idx, cv in enumerate(structured_cvs, 1):\n",
        "        cv_file = cv[\"file\"]\n",
        "        cv_data = cv[\"structured\"]\n",
        "        candidate_name = cv_data.get(\"name\", \"\").strip()\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"ã€{idx}/{len(structured_cvs)}ã€‘æ­£åœ¨å¤„ç†: {cv_file} | å§“å: {candidate_name}\")\n",
        "        print('='*60)\n",
        "\n",
        "\n",
        "        try:\n",
        "            async with mcp_client.session(\"social_graph\") as session:\n",
        "                raw_search = await session.call_tool(\n",
        "                    name=\"search_facebook_users\",\n",
        "                    arguments={\"q\": candidate_name, \"limit\": 1, \"fuzzy\": True}\n",
        "                )\n",
        "\n",
        "            search_result_data = json.loads(raw_search.content[0].text)\n",
        "            if not search_result_data:\n",
        "                print(f\"âš ï¸ æœªæ‰¾åˆ°åŒ¹é…ç”¨æˆ·ï¼Œè·³è¿‡ {cv_file}\")\n",
        "                final_results.append({\n",
        "                    \"file\": cv_file,\n",
        "                    \"status\": \"skipped\",\n",
        "                    \"reason\": \"no_matching_users\"\n",
        "                })\n",
        "                continue\n",
        "            best_user = search_result_data[0]\n",
        "            user_id = best_user[\"id\"]\n",
        "            print(f\"âœ… æ‰¾åˆ°åŒ¹é…ç”¨æˆ·: ID={user_id}, å§“å={best_user['display_name']}\")\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ æœç´¢å¤±è´¥: {str(e)}\")\n",
        "            final_results.append({\n",
        "                \"file\": cv_file,\n",
        "                \"status\": \"failed\",\n",
        "                \"stage\": \"search\",\n",
        "                \"error\": str(e)\n",
        "            })\n",
        "            continue\n",
        "\n",
        "\n",
        "        try:\n",
        "            async with mcp_client.session(\"social_graph\") as session:\n",
        "                raw_profile = await session.call_tool(\n",
        "                    name=\"get_facebook_profile\",\n",
        "                    arguments={\"user_id\": user_id}\n",
        "                )\n",
        "\n",
        "            profile_data = json.loads(raw_profile.content[0].text)\n",
        "            if not profile_data:\n",
        "                print(f\"âš ï¸ ç”¨æˆ·èµ„æ–™ä¸ºç©ºï¼Œè·³è¿‡ {cv_file}\")\n",
        "                final_results.append({\n",
        "                    \"file\": cv_file,\n",
        "                    \"status\": \"skipped\",\n",
        "                    \"reason\": \"empty_profile\"\n",
        "                })\n",
        "                continue\n",
        "            print(\"âœ… ç”¨æˆ·èµ„æ–™èŽ·å–æˆåŠŸ\")\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ èŽ·å–èµ„æ–™å¤±è´¥: {str(e)}\")\n",
        "            final_results.append({\n",
        "                \"file\": cv_file,\n",
        "                \"status\": \"failed\",\n",
        "                \"stage\": \"get_profile\",\n",
        "                \"error\": str(e)\n",
        "            })\n",
        "            continue\n",
        "\n",
        "\n",
        "        discrepancies = []\n",
        "\n",
        "        if profile_data.get(\"display_name\") and cv_data.get(\"name\"):\n",
        "            if not any(part.lower() in profile_data[\"display_name\"].lower() for part in cv_data[\"name\"].split()):\n",
        "                discrepancies.append({\n",
        "                    \"category\": \"Identity\",\n",
        "                    \"cv_claim\": cv_data[\"name\"],\n",
        "                    \"social_evidence\": profile_data[\"display_name\"],\n",
        "                    \"issue\": \"å§“åä¸åŒ¹é…\"\n",
        "                })\n",
        "\n",
        "        cv_schools = [edu.get(\"school\", \"\") for edu in cv_data.get(\"education\", [])]\n",
        "        social_edu = profile_data.get(\"education\", \"\")\n",
        "        for school in cv_schools:\n",
        "            if school and school not in social_edu:\n",
        "                discrepancies.append({\n",
        "                    \"category\": \"Education\",\n",
        "                    \"cv_claim\": school,\n",
        "                    \"social_evidence\": social_edu if social_edu else \"æœªå¡«å†™\",\n",
        "                    \"issue\": \"ç®€åŽ†ä¸­çš„å­¦æ ¡æœªåœ¨ç¤¾äº¤èµ„æ–™ä¸­ä½“çŽ°\"\n",
        "                })\n",
        "\n",
        "        cv_companies = [exp.get(\"company\", \"\") for exp in cv_data.get(\"work_experience\", [])]\n",
        "        social_company = profile_data.get(\"current_company\", \"\")\n",
        "        for company in cv_companies:\n",
        "            if company and social_company and company not in social_company:\n",
        "                discrepancies.append({\n",
        "                    \"category\": \"Employment\",\n",
        "                    \"cv_claim\": company,\n",
        "                    \"social_evidence\": social_company,\n",
        "                    \"issue\": \"ç®€åŽ†ä¸­çš„å…¬å¸ä¸Žç¤¾äº¤èµ„æ–™å½“å‰å…¬å¸ä¸ç¬¦\"\n",
        "                })\n",
        "\n",
        "\n",
        "        report = f\"# ðŸ“‹ CV éªŒè¯æŠ¥å‘Š - {cv_file}\\n\"\n",
        "        report += f\"## åŸºæœ¬ä¿¡æ¯\\n- å€™é€‰äººå§“å: {cv_data.get('name', 'N/A')}\\n\"\n",
        "        report += f\"- åŒ¹é…ç¤¾äº¤è´¦å·: {profile_data.get('display_name', 'æœªæ‰¾åˆ°')}\\n\"\n",
        "        if discrepancies:\n",
        "            report += f\"## ðŸ” å‘çŽ° {len(discrepancies)} å¤„å·®å¼‚:\\n\"\n",
        "            for i, d in enumerate(discrepancies, 1):\n",
        "                report += f\"{i}. **[{d['category']}] {d['issue']}**\\n   - ç®€åŽ†: {d['cv_claim']}\\n   - ç¤¾äº¤: {d['social_evidence']}\\n\"\n",
        "        else:\n",
        "            report += \"## ðŸ” æœªå‘çŽ°æ˜Žæ˜¾å·®å¼‚ï¼Œç®€åŽ†ä¿¡æ¯åˆæ­¥éªŒè¯é€šè¿‡ã€‚\\n\"\n",
        "        print(report)\n",
        "\n",
        "        final_results.append({\n",
        "            \"file\": cv_file,\n",
        "            \"status\": \"completed\",\n",
        "            \"cv_data\": cv_data,\n",
        "            \"social_data\": profile_data,\n",
        "            \"discrepancies\": discrepancies,\n",
        "            \"report\": report\n",
        "        })\n",
        "\n",
        "\n",
        "    with open(\"CV_Verification_Final_Report.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(final_results, f, ensure_ascii=False, indent=2)\n",
        "    print(f\"\\nðŸŽ‰ å…¨éƒ¨å¤„ç†å®Œæˆï¼å…±å¤„ç† {len(final_results)} ä»½ç®€åŽ†\")\n",
        "    print(\"ðŸ“„ å®Œæ•´æŠ¥å‘Šå·²ä¿å­˜ä¸º: CV_Verification_Final_Report.json\")\n",
        "\n",
        "\n",
        "await verify_all_cvs()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l33UX9p6B7-h",
        "outputId": "3e3c7be9-c743-4c6b-d5ed-9b499d90e626"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "ã€1/5ã€‘æ­£åœ¨å¤„ç†: CV_1.pdf | å§“å: John Smith\n",
            "============================================================\n",
            "âœ… æ‰¾åˆ°åŒ¹é…ç”¨æˆ·: ID=8, å§“å=John Smith\n",
            "âœ… ç”¨æˆ·èµ„æ–™èŽ·å–æˆåŠŸ\n",
            "# ðŸ“‹ CV éªŒè¯æŠ¥å‘Š - CV_1.pdf\n",
            "## åŸºæœ¬ä¿¡æ¯\n",
            "- å€™é€‰äººå§“å: John Smith\n",
            "- åŒ¹é…ç¤¾äº¤è´¦å·: John Smith\n",
            "## ðŸ” å‘çŽ° 2 å¤„å·®å¼‚:\n",
            "1. **[Education] ç®€åŽ†ä¸­çš„å­¦æ ¡æœªåœ¨ç¤¾äº¤èµ„æ–™ä¸­ä½“çŽ°**\n",
            "   - ç®€åŽ†: McGill University\n",
            "   - ç¤¾äº¤: Doctoral Degree\n",
            "2. **[Employment] ç®€åŽ†ä¸­çš„å…¬å¸ä¸Žç¤¾äº¤èµ„æ–™å½“å‰å…¬å¸ä¸ç¬¦**\n",
            "   - ç®€åŽ†: ByteDance\n",
            "   - ç¤¾äº¤: Hang Seng Bank\n",
            "\n",
            "\n",
            "============================================================\n",
            "ã€2/5ã€‘æ­£åœ¨å¤„ç†: CV_2.pdf | å§“å: Minh Pham\n",
            "============================================================\n",
            "âœ… æ‰¾åˆ°åŒ¹é…ç”¨æˆ·: ID=62, å§“å=Minh Pham\n",
            "âœ… ç”¨æˆ·èµ„æ–™èŽ·å–æˆåŠŸ\n",
            "# ðŸ“‹ CV éªŒè¯æŠ¥å‘Š - CV_2.pdf\n",
            "## åŸºæœ¬ä¿¡æ¯\n",
            "- å€™é€‰äººå§“å: Minh Pham\n",
            "- åŒ¹é…ç¤¾äº¤è´¦å·: Minh Pham\n",
            "## ðŸ” å‘çŽ° 3 å¤„å·®å¼‚:\n",
            "1. **[Education] ç®€åŽ†ä¸­çš„å­¦æ ¡æœªåœ¨ç¤¾äº¤èµ„æ–™ä¸­ä½“çŽ°**\n",
            "   - ç®€åŽ†: The University of Hong Kong\n",
            "   - ç¤¾äº¤: Master's Degree\n",
            "2. **[Employment] ç®€åŽ†ä¸­çš„å…¬å¸ä¸Žç¤¾äº¤èµ„æ–™å½“å‰å…¬å¸ä¸ç¬¦**\n",
            "   - ç®€åŽ†: BCG\n",
            "   - ç¤¾äº¤: Deloitte\n",
            "3. **[Employment] ç®€åŽ†ä¸­çš„å…¬å¸ä¸Žç¤¾äº¤èµ„æ–™å½“å‰å…¬å¸ä¸ç¬¦**\n",
            "   - ç®€åŽ†: Tencent\n",
            "   - ç¤¾äº¤: Deloitte\n",
            "\n",
            "\n",
            "============================================================\n",
            "ã€3/5ã€‘æ­£åœ¨å¤„ç†: CV_3.pdf | å§“å: Wei Zhang\n",
            "============================================================\n",
            "âœ… æ‰¾åˆ°åŒ¹é…ç”¨æˆ·: ID=76, å§“å=Wei Zhang\n",
            "âœ… ç”¨æˆ·èµ„æ–™èŽ·å–æˆåŠŸ\n",
            "# ðŸ“‹ CV éªŒè¯æŠ¥å‘Š - CV_3.pdf\n",
            "## åŸºæœ¬ä¿¡æ¯\n",
            "- å€™é€‰äººå§“å: Wei Zhang\n",
            "- åŒ¹é…ç¤¾äº¤è´¦å·: Wei Zhang\n",
            "## ðŸ” å‘çŽ° 2 å¤„å·®å¼‚:\n",
            "1. **[Education] ç®€åŽ†ä¸­çš„å­¦æ ¡æœªåœ¨ç¤¾äº¤èµ„æ–™ä¸­ä½“çŽ°**\n",
            "   - ç®€åŽ†: University of Tokyo\n",
            "   - ç¤¾äº¤: Master's Degree\n",
            "2. **[Employment] ç®€åŽ†ä¸­çš„å…¬å¸ä¸Žç¤¾äº¤èµ„æ–™å½“å‰å…¬å¸ä¸ç¬¦**\n",
            "   - ç®€åŽ†: PwC\n",
            "   - ç¤¾äº¤: Meta\n",
            "\n",
            "\n",
            "============================================================\n",
            "ã€4/5ã€‘æ­£åœ¨å¤„ç†: CV_4.pdf | å§“å: Rahul Sharma\n",
            "============================================================\n",
            "âœ… æ‰¾åˆ°åŒ¹é…ç”¨æˆ·: ID=4, å§“å=Rahul Sharma\n",
            "âœ… ç”¨æˆ·èµ„æ–™èŽ·å–æˆåŠŸ\n",
            "# ðŸ“‹ CV éªŒè¯æŠ¥å‘Š - CV_4.pdf\n",
            "## åŸºæœ¬ä¿¡æ¯\n",
            "- å€™é€‰äººå§“å: Rahul Sharma\n",
            "- åŒ¹é…ç¤¾äº¤è´¦å·: Rahul Sharma\n",
            "## ðŸ” å‘çŽ° 3 å¤„å·®å¼‚:\n",
            "1. **[Education] ç®€åŽ†ä¸­çš„å­¦æ ¡æœªåœ¨ç¤¾äº¤èµ„æ–™ä¸­ä½“çŽ°**\n",
            "   - ç®€åŽ†: Tsinghua University\n",
            "   - ç¤¾äº¤: Master's Degree\n",
            "2. **[Employment] ç®€åŽ†ä¸­çš„å…¬å¸ä¸Žç¤¾äº¤èµ„æ–™å½“å‰å…¬å¸ä¸ç¬¦**\n",
            "   - ç®€åŽ†: Microsoft\n",
            "   - ç¤¾äº¤: TechWorks\n",
            "3. **[Employment] ç®€åŽ†ä¸­çš„å…¬å¸ä¸Žç¤¾äº¤èµ„æ–™å½“å‰å…¬å¸ä¸ç¬¦**\n",
            "   - ç®€åŽ†: StartupXYZ\n",
            "   - ç¤¾äº¤: TechWorks\n",
            "\n",
            "\n",
            "============================================================\n",
            "ã€5/5ã€‘æ­£åœ¨å¤„ç†: CV_5.pdf | å§“å: Rahul Sharma\n",
            "============================================================\n",
            "âœ… æ‰¾åˆ°åŒ¹é…ç”¨æˆ·: ID=4, å§“å=Rahul Sharma\n",
            "âœ… ç”¨æˆ·èµ„æ–™èŽ·å–æˆåŠŸ\n",
            "# ðŸ“‹ CV éªŒè¯æŠ¥å‘Š - CV_5.pdf\n",
            "## åŸºæœ¬ä¿¡æ¯\n",
            "- å€™é€‰äººå§“å: Rahul Sharma\n",
            "- åŒ¹é…ç¤¾äº¤è´¦å·: Rahul Sharma\n",
            "## ðŸ” å‘çŽ° 5 å¤„å·®å¼‚:\n",
            "1. **[Education] ç®€åŽ†ä¸­çš„å­¦æ ¡æœªåœ¨ç¤¾äº¤èµ„æ–™ä¸­ä½“çŽ°**\n",
            "   - ç®€åŽ†: University of Tokyo\n",
            "   - ç¤¾äº¤: Master's Degree\n",
            "2. **[Employment] ç®€åŽ†ä¸­çš„å…¬å¸ä¸Žç¤¾äº¤èµ„æ–™å½“å‰å…¬å¸ä¸ç¬¦**\n",
            "   - ç®€åŽ†: EY\n",
            "   - ç¤¾äº¤: TechWorks\n",
            "3. **[Employment] ç®€åŽ†ä¸­çš„å…¬å¸ä¸Žç¤¾äº¤èµ„æ–™å½“å‰å…¬å¸ä¸ç¬¦**\n",
            "   - ç®€åŽ†: DataForge\n",
            "   - ç¤¾äº¤: TechWorks\n",
            "4. **[Employment] ç®€åŽ†ä¸­çš„å…¬å¸ä¸Žç¤¾äº¤èµ„æ–™å½“å‰å…¬å¸ä¸ç¬¦**\n",
            "   - ç®€åŽ†: StartupXYZ\n",
            "   - ç¤¾äº¤: TechWorks\n",
            "5. **[Employment] ç®€åŽ†ä¸­çš„å…¬å¸ä¸Žç¤¾äº¤èµ„æ–™å½“å‰å…¬å¸ä¸ç¬¦**\n",
            "   - ç®€åŽ†: UrbanFlow\n",
            "   - ç¤¾äº¤: TechWorks\n",
            "\n",
            "\n",
            "ðŸŽ‰ å…¨éƒ¨å¤„ç†å®Œæˆï¼å…±å¤„ç† 5 ä»½ç®€åŽ†\n",
            "ðŸ“„ å®Œæ•´æŠ¥å‘Šå·²ä¿å­˜ä¸º: CV_Verification_Final_Report.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lcKlUy_pqS91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================\n",
        "#  Evaluation code\n",
        "# =====================================================\n",
        "\n",
        "def evaluate(scores, groundtruth, threshold=0.5):\n",
        "    \"\"\"\n",
        "    scores: list of floats in [0, 1], length = 5\n",
        "    groundtruth: list of ints (0 or 1), length = 5\n",
        "    \"\"\"\n",
        "    assert len(scores) == 5\n",
        "    assert len(groundtruth) == 5\n",
        "\n",
        "    correct = 0\n",
        "    decisions = []\n",
        "\n",
        "    for s, gt in zip(scores, groundtruth):\n",
        "        pred = 1 if s > threshold else 0\n",
        "        decisions.append(pred)\n",
        "        if pred == gt:\n",
        "            correct += 1\n",
        "\n",
        "    final_score = correct / len(scores)\n",
        "\n",
        "    return {\n",
        "        \"decisions\": decisions,\n",
        "        \"correct\": correct,\n",
        "        \"total\": len(scores),\n",
        "        \"final_score\": final_score\n",
        "    }\n"
      ],
      "metadata": {
        "id": "0TtL07airIqz"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = [0.2, 0.3, 0.4, 0.5, 0.6]# Your code should generate this list [0.2, 0.3, 0.4, 0.5, 0.6]\n",
        "groundtruth = [1, 1, 1, 0, 0] # Do not modify\n",
        "\n",
        "result = evaluate(scores, groundtruth)\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J14ltXjPtaMF",
        "outputId": "0b89dcf2-064a-4c88-b5cd-d46033ce9cda"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'decisions': [0, 0, 0, 0, 1], 'correct': 1, 'total': 5, 'final_score': 0.2}\n"
          ]
        }
      ]
    }
  ]
}